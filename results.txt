ML Assignment 7: ANN
================================
Kialan Pillay: PLLKIA010
================================

PART I
----------
Question 1
----------
Input Layer  - 2 Nodes
Hidden Layer - 2 Nodes
Output Layer - 1 Node

3 Perceptrons Minimum - Fully Connected, Feed-Forward Network.
XOR can be decomposed into AND(OR,NAND).
Each Perceptron is a Basic Logic Gate.
Output Layer Perceptron - AND

Neural Network Evaluation - Test Data
-------------------------------------
[0.00, 0.00] - Prediction: 0.00
[0.00, 1.00] - Prediction: 1.00
[1.00, 0.00] - Prediction: 1.00
[1.00, 1.00] - Prediction: 0.00
[0.00, 1.10] - Prediction: 1.00
[0.90, 0.10] - Prediction: 1.00

Neural Network Accuracy: 100.00%
Mean Squared Error (MSE): 0.00

Question 2
----------
Training Examples (12)
4 Per Basic Logic Gate

Hidden Layer Perceptron 1
[0,0] - Label: 0
[0,1] - Label: 1
[1,0] - Label: 1
[1,1] - Label: 1
Hidden Layer Perceptron 2
[0,0] - Label: 1
[0,1] - Label: 1
[1,0] - Label: 1
[1,1] - Label: 0
Output Layer Perceptron
[0,0] - Label: 0
[0,1] - Label: 1
[1,0] - Label: 1
[1,1] - Label: 0

PART II
----------
Question 3
----------
Hidden Layer Output - [ 0.7631 0.8022 ]

Question 4
----------
Output Layer Neuron Output - 0.75

Question 5
----------
Mean Squared Error: 0.15